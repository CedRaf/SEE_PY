{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 For Clustering: Sessa Empirical Estimator\n",
    "- Read the Journals about the Sessa Empirical Estimator.\n",
    "\n",
    "- Convert the R codes into Python Codes (use jupyter notebook).\n",
    "\n",
    "- Using Simulated data or a real world datasets of your choice, perform the Sessa Empircal Estimator and generate some insights.\n",
    "    - https://www.frontiersin.org/journals/pharmacology/articles/10.3389/fphar.2019.00383/full\n",
    "    - https://archive.ics.uci.edu/\n",
    "\n",
    "- The Sessa Empirical Estimator uses K-Means clustering (again recall the disadvantages of K-Means), try to substitute a different clustering algorithm, generate a new insight using the new clustering algorithm.\n",
    "\n",
    "- Compare your results between Sessa Empirical Estimator using K-Means, and Sessa Empirical Estimator using the clustering algorithm of your choice.\n",
    "\n",
    "- Deadline is this Sunday, Feb 23, 2022 at 11:59 pm\n",
    "\n",
    "- Do this with your thesis partner.\n",
    "\n",
    "- You can use any A.I. assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import equivalent libraries from R to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(AdhereR)\n",
    "library(dplyr)\n",
    "library(plyr)\n",
    "library(lubridate)\n",
    "library(latticeExtra)\n",
    "library(data.table)\n",
    "library(factoextra)\n",
    "library(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import norm\n",
    "from sklearn import decomposition, preprocessing\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert and generate simulated data from article provided\n",
    "- https://github.com/Masswear/BeyondThresholds/blob/master/Code/functions.R\n",
    "\n",
    "- Asked GPT for the equivalent R functions in Python\n",
    "    - i.e what in the world qnorm() is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP</th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>ATC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>30</td>\n",
       "      <td>Med_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>60</td>\n",
       "      <td>Med_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>30</td>\n",
       "      <td>Med_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>30</td>\n",
       "      <td>Med_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>30</td>\n",
       "      <td>Med_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>6</td>\n",
       "      <td>98</td>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>60</td>\n",
       "      <td>Med_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>30</td>\n",
       "      <td>Med_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>2022-02-07</td>\n",
       "      <td>60</td>\n",
       "      <td>Med_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>30</td>\n",
       "      <td>Med_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>2022-02-21</td>\n",
       "      <td>90</td>\n",
       "      <td>Med_B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GROUP  PATIENT_ID        DATE  DURATION    ATC\n",
       "0        1           1  2022-01-01        30  Med_C\n",
       "1        1           1  2022-02-01        60  Med_C\n",
       "2        1           1  2022-04-11        30  Med_C\n",
       "3        1           2  2022-01-01        30  Med_A\n",
       "4        1           2  2022-01-29        30  Med_A\n",
       "..     ...         ...         ...       ...    ...\n",
       "291      6          98  2022-05-17        60  Med_C\n",
       "292      6          99  2022-01-01        30  Med_C\n",
       "293      6          99  2022-02-07        60  Med_C\n",
       "294      6         100  2022-01-01        30  Med_B\n",
       "295      6         100  2022-02-21        90  Med_B\n",
       "\n",
       "[296 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def logistics(x, L=0, S=1, D=1, h=1, B=None): #used in groups 4 and 5\n",
    "    if B is None:\n",
    "        B = x - D\n",
    "    y = (h-(5*L))/(1 + np.exp(S*B)) + L\n",
    "    return y\n",
    "\n",
    "def med_events_sample(ntot, start_date=\"01.01.2022\", tot_duration=2*365, disp_durations=[30, 60, 90], dist_durations=[0.3, 0.5, 0.2], dist=[0.1, 0.2, 0.2, 0.2, 0.2, 0.1]):\n",
    "    def offset(group, n): #gives back an array of offset dates based on the group number of assigned patient\n",
    "        if group == 1:\n",
    "            L, U, m, s = -0.1, 0.2, 0.05, 0.1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "        elif group == 2:\n",
    "            L, U, m, s = -0.2, 1.2, 0, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "        elif group == 3:\n",
    "            L, U, m, s = 0.5, 1.5, 1, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset1 = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "            t = 2/n * np.arange(1, n+1)\n",
    "            offset = t* offset1\n",
    "        elif group == 4:\n",
    "            L, U, m, s = 0.8, 1.2, 1, 0.1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset1 = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "            offset = logistics(x=np.arange(1, n+1), L=0.05, S=10, D=n, B=np.sin(2*np.arange(1, n+1)-n))*offset1\n",
    "        elif group == 5:\n",
    "            L, U, m, s = 0.5, 1.5, 1, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset1 = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "            offset = logistics(x=np.arange(1, n+1), L=0.05, S=-15, D=n/3)*offset1\n",
    "        elif group == 6:\n",
    "            n =  np.random.choice([2,3])\n",
    "            L, U, m, s = -0.2, 0.8, 0.3, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "\n",
    "        return offset\n",
    "\n",
    "    def refills(x, group): #fills all entries of refill dates for 1 patient \n",
    "        initial_fill = 30\n",
    "        offsets = offset(group=group, n=len(disp_durations))\n",
    "\n",
    "        durations = np.random.choice(disp_durations, size=len(offsets)-1, replace=True, p=dist_durations)\n",
    "        durations = np.insert(durations, 0, initial_fill)\n",
    "\n",
    "        date = datetime.strptime(start_date, \"%d.%m.%Y\").date()\n",
    "\n",
    "        refill_dates = [date] + [date + timedelta(days=int(sum(durations[:i+1]) + round(offsets[i] * durations[i], 0))) for i in range(len(durations))] #might be the cause of only 3 refill dates every patient\n",
    "\n",
    "        medicine_type = np.random.choice(['Med_A', 'Med_B', 'Med_C'])\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'GROUP': group,\n",
    "            'PATIENT_ID': x, \n",
    "            'DATE': refill_dates[:-1],\n",
    "            'DURATION': durations,\n",
    "            'ATC' : medicine_type\n",
    "        })\n",
    "        \n",
    "\n",
    "        return df\n",
    "\n",
    "    ID_last = 0\n",
    "    sample = pd.DataFrame()\n",
    "    \n",
    "    mean_duration = np.sum(np.array(disp_durations) * np.array(dist_durations))\n",
    "\n",
    "    n = int(np.ceil((tot_duration/mean_duration) * 1.5))\n",
    "\n",
    "    temp_samples = []\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        num_pat = round(dist[i-1] * ntot) #this evenly spaces out the patients sequentially to each group, i think this should be changed to random\n",
    "        ID_first = ID_last + 1\n",
    "        ID_last = ID_first + num_pat - 1\n",
    "        temp_groups = [refills(x, i) for x in range(ID_first, ID_last + 1)]\n",
    "        temp_groups = [g for g in temp_groups if not g.empty]  # Remove empty DataFrames\n",
    "\n",
    "        if temp_groups:\n",
    "            group = pd.concat(temp_groups)\n",
    "            temp_samples.append(group)\n",
    "\n",
    "    num_pat = ntot - ID_last\n",
    "    ID_first = ID_last + 1\n",
    "    ID_last = ID_first + num_pat - 1\n",
    "    temp_groups = [refills(x, 6) for x in range(ID_first, ID_last + 1)] #meant to assign any leftovers to group6\n",
    "    temp_groups = [g for g in temp_groups if not g.empty] \n",
    "\n",
    "    if temp_groups: \n",
    "        group = pd.concat(temp_groups) \n",
    "        temp_samples.append(group)\n",
    "        sample.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    if temp_samples:\n",
    "        sample = pd.concat(temp_samples)\n",
    "        sample.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if sample.empty:\n",
    "        print(\"No data was generated!\")\n",
    "    else:\n",
    "        display(sample)\n",
    "        # sample.to_csv(\"med_events_sample.csv\", index=False)\n",
    "        # print(\"CSV file saved: med_events_sample.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ntot = 100  # Example number of patients\n",
    "    med_events_sample(ntot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the Sessa Empirical Estimation from R to Python\n",
    "- See the SEE.R file found in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"med_events_sample.csv\")\n",
    "def see(df, med_type):\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    df_filtered = df[df[\"ATC\"] == med_type].copy()\n",
    "    df_filtered = df_filtered.sort_values(by=[\"PATIENT_ID\", \"DATE\"])\n",
    "\n",
    "    df_filtered[\"PREV_DATE\"] = df_filtered.groupby(\"PATIENT_ID\")[\"DATE\"].shift(1)\n",
    "    df_filtered = df_filtered.dropna(subset=[\"PREV_DATE\"])\n",
    "\n",
    "    df_sampled = df_filtered.groupby(\"PATIENT_ID\").sample(n=1, random_state=42)\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    df_filtered[\"PREV_DATE\"] = pd.to_datetime(df_filtered[\"PREV_DATE\"])\n",
    "    df_sampled[\"EVENT_INTERVAL\"] = (df_sampled[\"DATE\"] - df_sampled[\"PREV_DATE\"]).dt.days\n",
    "    ecdf = ECDF(df_sampled[\"EVENT_INTERVAL\"])\n",
    "    df_ecdf = pd.DataFrame({\"x\": ecdf.x, \"y\": ecdf.y})\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(df_ecdf[\"x\"], df_ecdf[\"y\"], marker=\".\", linestyle=\"none\", label=\"ECDF\")\n",
    "    plt.xlabel(\"Event Interval (Days)\")\n",
    "    plt.ylabel(\"ECDF\")\n",
    "    plt.title(f\"Empirical CDF for {med_type}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    #Keeping 20% of the ECDF\n",
    "\n",
    "    df_ecdf_80 = df_ecdf[df_ecdf[\"y\"] <=0.8]\n",
    "    ni = df_ecdf[\"x\"].max()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(df_ecdf_80[\"x\"], df_ecdf_80[\"y\"], marker=\".\", linestyle=\"none\", color=\"red\")\n",
    "    plt.xlabel(\"Event Interval (Days)\")\n",
    "    plt.ylabel(\"ECDF\")\n",
    "    plt.title(\"80% ECDF\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(df_ecdf[\"x\"], df_ecdf[\"y\"], marker=\".\", linestyle=\"none\")\n",
    "    plt.xlabel(\"Event Interval (Days)\")\n",
    "    plt.ylabel(\"ECDF\")\n",
    "    plt.title(\"100% ECDF\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    df_filtered = df_sampled[df_sampled[\"EVENT_INTERVAL\"] <= ni]\n",
    "\n",
    "    log_intervals = np.log(df_filtered[\"EVENT_INTERVAL\"])\n",
    "    density = gaussian_kde(log_intervals)\n",
    "\n",
    "    x_vals = np.linspace(log_intervals.min(), log_intervals.max(), 100)\n",
    "    y_vals = density(x_vals)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(x_vals, y_vals)\n",
    "    plt.xlabel(\"Log(Event Interval)\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Log(Event Interval) Density Plot\")\n",
    "    plt.show()\n",
    "\n",
    "    df_density = pd.DataFrame({\"x\": x_vals, \"y\": y_vals})\n",
    "    df_density = df_density.astype(float)\n",
    "    df_scaled = (df_density - df_density.mean()) / df_density.std()  \n",
    "\n",
    "    #Silhoutte Score\n",
    "\n",
    "    best_k = None\n",
    "    best_score = -1\n",
    "    cluster_range = range(2,10)\n",
    "\n",
    "    for k in cluster_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(df_scaled)\n",
    "        score = silhouette_score(df_scaled, labels)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_k = k\n",
    "            best_score = score\n",
    "\n",
    "    print(f\"Optimal number of clusters: {best_k}, Silhoutte Score: {best_score:.4f}\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "    visualizer = SilhouetteVisualizer(kmeans, ax=ax)\n",
    "    visualizer.fit(df_scaled)\n",
    "    visualizer.show()\n",
    "\n",
    "\n",
    "testData = see(dataset, \"Med_A\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
