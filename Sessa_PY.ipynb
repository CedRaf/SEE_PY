{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 For Clustering: Sessa Empirical Estimator\n",
    "- Read the Journals about the Sessa Empirical Estimator.\n",
    "\n",
    "- Convert the R codes into Python Codes (use jupyter notebook).\n",
    "\n",
    "- Using Simulated data or a real world datasets of your choice, perform the Sessa Empircal Estimator and generate some insights.\n",
    "    - https://www.frontiersin.org/journals/pharmacology/articles/10.3389/fphar.2019.00383/full\n",
    "    - https://archive.ics.uci.edu/\n",
    "\n",
    "- The Sessa Empirical Estimator uses K-Means clustering (again recall the disadvantages of K-Means), try to substitute a different clustering algorithm, generate a new insight using the new clustering algorithm.\n",
    "\n",
    "- Compare your results between Sessa Empirical Estimator using K-Means, and Sessa Empirical Estimator using the clustering algorithm of your choice.\n",
    "\n",
    "- Deadline is this Sunday, Feb 23, 2022 at 11:59 pm\n",
    "\n",
    "- Do this with your thesis partner.\n",
    "\n",
    "- You can use any A.I. assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import equivalent libraries from R to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(AdhereR)\n",
    "library(dplyr)\n",
    "library(plyr)\n",
    "library(lubridate)\n",
    "library(latticeExtra)\n",
    "library(data.table)\n",
    "library(factoextra)\n",
    "library(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import norm\n",
    "from sklearn import decomposition, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert and generate simulated data from article provided\n",
    "- https://github.com/Masswear/BeyondThresholds/blob/master/Code/functions.R\n",
    "\n",
    "- Asked GPT for the equivalent R functions in Python\n",
    "    - i.e what in the world qnorm() is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistics(x, L=0, S=1, D=1, h=1, B=None):\n",
    "    if B is None:\n",
    "        B = x - D\n",
    "    y = (h-(5*L))/(1 + np.exp(S*B)) + L\n",
    "    return y\n",
    "\n",
    "def med_events_sample(ntot, start_date=\"01.01.2022\", tot_duration=2*365, disp_durations=[30, 60, 90], dist_durations=[0.3, 0.5, 0.2], dist=[0.1, 0.2, 0.2, 0.2, 0.2, 0.1]):\n",
    "    def offset(group, n):\n",
    "        if group == 1:\n",
    "            L, U, m, s = -0.1, 0.2, 0.05, 0.1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "        elif group == 2:\n",
    "            L, U, m, s = -0.2, 1.2, 0, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "        elif group == 3:\n",
    "            L, U, m, s = 0.5, 1.5, 1, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset1 = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "            t = 2/n * np.arange(1, n+1)\n",
    "            offset = t* offset1\n",
    "        elif group == 4:\n",
    "            L, U, m, s = 0.8, 1.2, 1, 0.1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset1 = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "            offset = logistics(x=np.arange(1, n+1), L=0.05, S=10, D=n, B=np.sin(2*np.arange(1, n+1)-n))*offset1\n",
    "        elif group == 5:\n",
    "            L, U, m, s = 0.5, 1.5, 1, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset1 = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "            offset = logistics(x=np.arange(1, n+1), L=0.05, S=-15, D=n/3)*offset1\n",
    "        elif group == 6:\n",
    "            n =  np.random.choice([2,3])\n",
    "            L, U, m, s = -0.2, 0.8, 0.3, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "\n",
    "        return offset\n",
    "\n",
    "    def refills(x, group):\n",
    "        initial_fill = 30\n",
    "        offsets = offset(group=group)\n",
    "\n",
    "        durations = np.random.choice(disp_durations, size=len(offsets)-1, replace=True, p=dist_durations)\n",
    "        durations = np.insert(durations, 0, initial_fill)\n",
    "\n",
    "        date = datetime.strptime(start_date, \"%d.%m.%Y\").date()\n",
    "\n",
    "        refill_dates = [date] + [date + timedelta(days=int(sum(durations[:i+1]) + round(offsets[i] * durations[i], 0))) for i in range(len(durations))]\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'GROUP': group,\n",
    "            'PATIENT_ID': x, \n",
    "            'DATE': refill_dates[:-1],\n",
    "            'DURATION': durations\n",
    "        })\n",
    "\n",
    "        return df\n",
    "\n",
    "    ID_last = 0\n",
    "    sample = pd.DataFrame()\n",
    "    \n",
    "    mean_duration = np.sum(np.array(disp_durations) * np.array(dist_durations))\n",
    "\n",
    "    n = int(np.ceil((tot_duration/mean_duration) * 1.5))\n",
    "\n",
    "    temp_samples = []\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        num_pat = round(dist[i-1] * ntot)\n",
    "        ID_first = ID_last + 1\n",
    "        ID_last = ID_first + num_pat - 1\n",
    "        group = pd.concat([refills(x, i, offset, disp_durations, dist_durations, start_date) for x in range(ID_first, ID_last + 1)])\n",
    "        temp_samples.append(group)\n",
    "\n",
    "    num_pat = ntot - ID_last\n",
    "    ID_first = ID_last + 1\n",
    "    ID_last = ID_first + num_pat - 1\n",
    "    group = pd.concat([refills(x, 6, offset, disp_durations, dist_durations, start_date) for x in range(ID_first, ID_last + 1)])\n",
    "    temp_samples.append(group)\n",
    "\n",
    "    sample = pd.concat(temp_samples)\n",
    "    print(sample)\n",
    "        \n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
