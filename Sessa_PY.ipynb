{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 For Clustering: Sessa Empirical Estimator\n",
    "- Read the Journals about the Sessa Empirical Estimator.\n",
    "\n",
    "- Convert the R codes into Python Codes (use jupyter notebook).\n",
    "\n",
    "- Using Simulated data or a real world datasets of your choice, perform the Sessa Empircal Estimator and generate some insights.\n",
    "    - https://www.frontiersin.org/journals/pharmacology/articles/10.3389/fphar.2019.00383/full\n",
    "    - https://archive.ics.uci.edu/\n",
    "\n",
    "- The Sessa Empirical Estimator uses K-Means clustering (again recall the disadvantages of K-Means), try to substitute a different clustering algorithm, generate a new insight using the new clustering algorithm.\n",
    "\n",
    "- Compare your results between Sessa Empirical Estimator using K-Means, and Sessa Empirical Estimator using the clustering algorithm of your choice.\n",
    "\n",
    "- Deadline is this Sunday, Feb 23, 2022 at 11:59 pm\n",
    "\n",
    "- Do this with your thesis partner.\n",
    "\n",
    "- You can use any A.I. assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import equivalent libraries from R to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library(AdhereR)\n",
    "# library(dplyr)\n",
    "# library(plyr)\n",
    "# library(lubridate)\n",
    "# library(latticeExtra)\n",
    "# library(data.table)\n",
    "# library(factoextra)\n",
    "# library(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import norm\n",
    "from sklearn import decomposition, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert and generate simulated data from article provided\n",
    "- https://github.com/Masswear/BeyondThresholds/blob/master/Code/functions.R\n",
    "\n",
    "- Asked GPT for the equivalent R functions in Python\n",
    "    - i.e what in the world qnorm() is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GROUP  PATIENT_ID        DATE  DURATION\n",
      "0       1           1  2022-01-01        30\n",
      "1       1           1  2022-02-01        30\n",
      "2       1           1  2022-03-05        60\n",
      "0       1           2  2022-01-01        30\n",
      "1       1           2  2022-02-02        60\n",
      "..    ...         ...         ...       ...\n",
      "2       6          98  2022-03-19        60\n",
      "0       6          99  2022-01-01        30\n",
      "1       6          99  2022-02-24        90\n",
      "0       6         100  2022-01-01        30\n",
      "1       6         100  2022-01-29        30\n",
      "\n",
      "[293 rows x 4 columns]\n",
      "CSV file saved: med_events_sample.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import norm\n",
    "from sklearn import decomposition, preprocessing\n",
    "\n",
    "def logistics(x, L=0, S=1, D=1, h=1, B=None): #used in groups 4 and 5\n",
    "    if B is None:\n",
    "        B = x - D\n",
    "    y = (h-(5*L))/(1 + np.exp(S*B)) + L\n",
    "    return y\n",
    "\n",
    "def med_events_sample(ntot, start_date=\"01.01.2022\", tot_duration=2*365, disp_durations=[30, 60, 90], dist_durations=[0.3, 0.5, 0.2], dist=[0.1, 0.2, 0.2, 0.2, 0.2, 0.1]):\n",
    "    def offset(group, n): #gives back an array of offset dates based on the group number of assigned patient\n",
    "        if group == 1:\n",
    "            L, U, m, s = -0.1, 0.2, 0.05, 0.1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "        elif group == 2:\n",
    "            L, U, m, s = -0.2, 1.2, 0, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "        elif group == 3:\n",
    "            L, U, m, s = 0.5, 1.5, 1, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset1 = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "            t = 2/n * np.arange(1, n+1)\n",
    "            offset = t* offset1\n",
    "        elif group == 4:\n",
    "            L, U, m, s = 0.8, 1.2, 1, 0.1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset1 = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "            offset = logistics(x=np.arange(1, n+1), L=0.05, S=10, D=n, B=np.sin(2*np.arange(1, n+1)-n))*offset1\n",
    "        elif group == 5:\n",
    "            L, U, m, s = 0.5, 1.5, 1, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset1 = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "            offset = logistics(x=np.arange(1, n+1), L=0.05, S=-15, D=n/3)*offset1\n",
    "        elif group == 6:\n",
    "            n =  np.random.choice([2,3])\n",
    "            L, U, m, s = -0.2, 0.8, 0.3, 1\n",
    "            pL, pU = norm.cdf(L, m, s), norm.cdf(U, m, s)\n",
    "            offset = norm.ppf(np.random.uniform(pL, pU, n), m, s)\n",
    "\n",
    "        return offset\n",
    "\n",
    "    def refills(x, group): #fills all entries of refill dates for 1 patient \n",
    "        initial_fill = 30\n",
    "        offsets = offset(group=group, n=len(disp_durations))\n",
    "\n",
    "        durations = np.random.choice(disp_durations, size=len(offsets)-1, replace=True, p=dist_durations)\n",
    "        durations = np.insert(durations, 0, initial_fill)\n",
    "\n",
    "        date = datetime.strptime(start_date, \"%d.%m.%Y\").date()\n",
    "\n",
    "        refill_dates = [date] + [date + timedelta(days=int(sum(durations[:i+1]) + round(offsets[i] * durations[i], 0))) for i in range(len(durations))] #might be the cause of only 3 refill dates every patient\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'GROUP': group,\n",
    "            'PATIENT_ID': x, \n",
    "            'DATE': refill_dates[:-1],\n",
    "            'DURATION': durations\n",
    "        })\n",
    "\n",
    "        return df\n",
    "\n",
    "    ID_last = 0\n",
    "    sample = pd.DataFrame()\n",
    "    \n",
    "    mean_duration = np.sum(np.array(disp_durations) * np.array(dist_durations))\n",
    "\n",
    "    n = int(np.ceil((tot_duration/mean_duration) * 1.5))\n",
    "\n",
    "    temp_samples = []\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        num_pat = round(dist[i-1] * ntot) #this evenly spaces out the patients sequentially to each group, i think this should be changed to random\n",
    "        ID_first = ID_last + 1\n",
    "        ID_last = ID_first + num_pat - 1\n",
    "        temp_groups = [refills(x, i) for x in range(ID_first, ID_last + 1)]\n",
    "        temp_groups = [g for g in temp_groups if not g.empty]  # Remove empty DataFrames\n",
    "\n",
    "        if temp_groups:\n",
    "            group = pd.concat(temp_groups)\n",
    "            temp_samples.append(group)\n",
    "\n",
    "    num_pat = ntot - ID_last\n",
    "    ID_first = ID_last + 1\n",
    "    ID_last = ID_first + num_pat - 1\n",
    "    temp_groups = [refills(x, 6) for x in range(ID_first, ID_last + 1)] #meant to assign any leftovers to group6\n",
    "    temp_groups = [g for g in temp_groups if not g.empty] \n",
    "\n",
    "    if temp_groups: \n",
    "        group = pd.concat(temp_groups) \n",
    "        temp_samples.append(group)\n",
    "\n",
    "    if temp_samples:\n",
    "        sample = pd.concat(temp_samples)\n",
    "\n",
    "    if sample.empty:\n",
    "        print(\"No data was generated!\")\n",
    "    else:\n",
    "        print(sample)\n",
    "        # sample.to_csv(\"med_events_sample.csv\", index=False)\n",
    "        # print(\"CSV file saved: med_events_sample.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ntot = 100  # Example number of patients\n",
    "    med_events_sample(ntot)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
